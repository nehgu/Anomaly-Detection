{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to read the input dataset as per the prescribed format in the feature map.\n",
    "def readGermanCreditDataset(fname):\n",
    "    inputData = []\n",
    "# inputData = np.fromfile(\"german.adcg.trainingd\", dtype=dt)#np.loadtxt(\"german.adcg.trainingd\", comments=\"#\", delimiter=\",\", unpack=False)#np.loadtxt('german.adcg.trainingd')\n",
    "    f = open(fname,'r')\n",
    "    featureMap = {'A11':1,'A12':2,'A13':3,'A14':4,\n",
    "                  'A30':1,'A31':2,'A32':3,'A33':4,'A34':5,\n",
    "                  'A40':1,'A41':2,'A42':3,'A43':4,'A44':5, 'A45':6,'A46':7,'A47':8,'A48':9,'A49':10, 'A410':0,\n",
    "                  'A61':2,'A62':3,'A63':4,'A64':5,'A65':1,\n",
    "                  'A71':1,'A72':2,'A73':3,'A74':4,'A75':5,\n",
    "                  'A91':1,'A92':4,'A93':2,'A94':3,'A95':4,\n",
    "                  'A101':1,'A102':2,'A103':3,\n",
    "                  'A121':4,'A122':3,'A123':2,'A124':1,\n",
    "                  'A141':1,'A142':2,'A143':3,\n",
    "                  'A151':2,'A152':3,'A153':1,\n",
    "                  'A171':1,'A172':2,'A173':3, 'A174':4,\n",
    "                  'A191':1,'A192':2,\n",
    "                  'A201':1,'A202':2}\n",
    "    for line in f:\n",
    "    #     inputLine = np.empty(shape=(1,20))\n",
    "        inputLine = []\n",
    "        numericalData = []\n",
    "        for word in line.split():\n",
    "            if word in featureMap:\n",
    "    #             print featureMap[word]\n",
    "                inputLine.append(featureMap[word])\n",
    "            else:\n",
    "#                 inputLine.append(int(word))\n",
    "                numericalData.append(int(word))\n",
    "#         inputData.append(inputLine)\n",
    "        inputData.append((inputLine + numericalData))\n",
    "    f.close()\n",
    "#     print inputData[0]\n",
    "    inputDatanp = np.array(inputData)\n",
    "\n",
    "    return inputDatanp\n",
    "\n",
    "\n",
    "#print trainedLabels[:3]\n",
    "\n",
    "\n",
    "# Function to write predicted labels for the Test dataset to a file.\n",
    "def writePrdictedLabelFile(YPred):\n",
    "    f = open(\"german.adcg.testing.label\",\"w\")\n",
    "    f.write(\"Id,Prediction\" + \"\\n\")\n",
    "\n",
    "    for i in xrange(len(YPred)):\n",
    "        f.write(str(i+1) + \",\" + str(YPred[i])+ \"\\n\")\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "# Read the input data and labels\n",
    "XTrain = readGermanCreditDataset(\"german.adcg.trainingd\")\n",
    "XTest = readGermanCreditDataset(\"german.adcg.testingd\")\n",
    "Y = np.loadtxt(\"german.adcg.training.label\", delimiter=\",\", skiprows=1, usecols=(1,))\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encTrain1 = OneHotEncoder()\n",
    "encTrain = encTrain1.fit_transform(XTrain[:,:12]).toarray()\n",
    "\n",
    "encTest1 = OneHotEncoder()\n",
    "encTest = encTest1.fit_transform(XTest[:,:12]).toarray()\n",
    "\n",
    "encNTrain = XTrain[:,13:]\n",
    "encNTest = XTest[:,13:]\n",
    "print XTest.shape, XTrain.shape\n",
    "print encNTest.shape, encNTrain.shape\n",
    "\n",
    "# XTrain = np.concatenate((encTrain, encNTrain), axis=1)\n",
    "# XTest = np.concatenate((encTest, encNTest), axis=1)\n",
    "\n",
    "#Normalizing & scaling of data\n",
    "from sklearn import preprocessing\n",
    "# encNTrain = preprocessing.scale(encNTrain)\n",
    "encNTrain = (encNTrain - encNTrain.mean())/encNTrain.std()\n",
    "# encNTest = preprocessing.scale(encNTest)\n",
    "encNTest = (encNTest - encNTest.mean())/encNTest.std()\n",
    "\n",
    "#c = XTrain.reshape((500, 52))\n",
    "XTrain = np.append(encTrain,encNTrain,axis=1)\n",
    "XTest = np.append(encTest,encNTest,axis=1)\n",
    "\n",
    "print XTrain.shape\n",
    "print XTest.shape\n",
    "\n",
    "\n",
    "#Split Training Data into Train & Validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "np.random.seed(9)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(XTrain[:,:12], Y, test_size=0.8)\n",
    "X_train, X_test, y_train, y_test = train_test_split(XTrain, Y, test_size=0.8)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(encNTrain, Y, test_size=0.8)\n",
    "XTrain = X_train\n",
    "XTest = X_test\n",
    "Y = y_train\n",
    "YTest = y_test\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "train_error = np.empty(5)\n",
    "test_error = np.empty(5)\n",
    "for degree in xrange(1,6):\n",
    "    est = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    est.fit(X_train, y_train)\n",
    "    train_error[degree-1] = mean_squared_error(y_train, est.predict(X_train))\n",
    "    test_error[degree-1] = mean_squared_error(y_test, est.predict(X_test))\n",
    "print train_error\n",
    "print test_error\n",
    "\n",
    "plt.plot(np.arange(5), train_error, color='green', label='train')\n",
    "plt.plot(np.arange(5), test_error, color='red', label='test')\n",
    "plt.ylim((0.0, 1e0))\n",
    "plt.ylabel('log(mean squared error)')\n",
    "plt.xlabel('degree')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()\n",
    "\n",
    "# Linear Regression\n",
    "\n",
    "from sklearn import linear_model\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# pca = PCA(n_components=48)\n",
    "# print XTrain.shape\n",
    "# pca.fit(XTrain)\n",
    "# XTrain = pca.transform(XTrain)\n",
    "# pca.fit(XTest)\n",
    "# XTest = pca.transform(XTest)\n",
    "# print XTrain.shape\n",
    "LR = linear_model.LinearRegression()\n",
    "LR.fit(XTrain, Y)\n",
    "# # LR.fit(encTrain, Y)\n",
    "\n",
    "# Finds the optimal model parameters using a least squares method.\n",
    "\n",
    "# To get the parameter values:\n",
    "LR.get_params()\n",
    "\n",
    "# To predict a new input XTest,\n",
    "YPred = LR.predict(XTest)\n",
    "# YPred = LR.predict(encTest)\n",
    "\n",
    "\n",
    "writePrdictedLabelFile(YPred)\n",
    "\n",
    "# # Regularization - Tune the parameter lambda to prevent overfitting.\n",
    "\n",
    "\n",
    "# # R^2 statistics to observe the goodness of a line fitting.\n",
    "# LR.score(XTest, Y)\n",
    "\n",
    "# # Submission Score 0.61265\n",
    "\n",
    "\n",
    "\n",
    "# # Ridge\n",
    "# clfR = linear_model.RidgeCV(alphas=[0.1, 0.3, 0.7, 1.0, 1.3, 1.7, 2, 2.3, 5, 7, 15, 50, 100])\n",
    "# clfR.fit(XTrain, Y)\n",
    "# print clfR.alpha_\n",
    "\n",
    "\n",
    "# # Lasso\n",
    "# clflml = linear_model.Lasso(alpha = 0.3)\n",
    "\n",
    "# Bayesian\n",
    "# clflml = linear_model.BayesianRidge()\n",
    "# clflml.fit(XTrain, Y)\n",
    "# YPred = clflml.predict(XTest)\n",
    "# writePrdictedLabelFile(YPred)\n",
    "\n",
    "# ARDRegression\n",
    "clflml = linear_model.ARDRegression(compute_score=True)\n",
    "clflml.fit(XTrain, Y)\n",
    "YPred = clflml.predict(XTest)\n",
    "writePrdictedLabelFile(YPred)\n",
    "\n",
    "\n",
    "\n",
    "# # Logistic Regression\n",
    "\n",
    "# LogReg = linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None)\n",
    "\n",
    "# LogReg.fit(XTrain, Y)\n",
    "\n",
    "# # Finds the optimal model parameters using a least squares method.\n",
    "\n",
    "# # To get the parameter values:\n",
    "# LogReg.get_params()\n",
    "\n",
    "# # To predict a new input XTest,\n",
    "# YPred = LogReg.predict(XTest)\n",
    "\n",
    "# writePrdictedLabelFile(YPred)\n",
    "\n",
    "# # Submission Score 0.54007\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Support Vector Machines (SVM)\n",
    "\n",
    "\n",
    "# from sklearn import svm\n",
    "\n",
    "# clf = svm.SVC()\n",
    "# clf.fit(XTrain, Y)  \n",
    "\n",
    "# # To predict a new input XTest\n",
    "# YPred = clf.predict(XTest)\n",
    "\n",
    "# writePrdictedLabelFile(YPred)\n",
    "\n",
    "# # Submission Score 0.50000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Multi-class classification - Linear SVM\n",
    "\n",
    "# lin_clf = svm.LinearSVC()\n",
    "# lin_clf.fit(XTrain, Y)\n",
    "\n",
    "# # To predict a new input XTest\n",
    "# YPred = lin_clf.predict(XTest)\n",
    "\n",
    "# writePrdictedLabelFile(YPred)\n",
    "\n",
    "# # Submission Score 0.58125\n",
    "\n",
    "\n",
    "\n",
    "# # Non Linear SVM\n",
    "\n",
    "# clfnl = svm.NuSVC()\n",
    "# clfnl.fit(XTrain, Y)\n",
    "\n",
    "# # To predict a new input XTest\n",
    "# YPred = clfnl.predict(XTest)\n",
    "\n",
    "# writePrdictedLabelFile(YPred)\n",
    "\n",
    "# # Submission Score 0.50037\n",
    "\n",
    "\n",
    "\n",
    "# SVM Kernels\n",
    "# print 'SVM Starting'\n",
    "# pca = PCA(n_components=48)\n",
    "# pca.fit(XTrain)\n",
    "# XTrain = pca.transform(XTrain)\n",
    "# pca.fit(XTest)\n",
    "# XTest = pca.transform(XTest)\n",
    "# # print XTrain.shape\n",
    "# linear_svc = svm.SVC(kernel='linear')\n",
    "# print linear_svc.kernel\n",
    "# linear_svc.fit(XTrain, Y)\n",
    "# print 'SVM Starting'\n",
    "# # To predict a new input XTest\n",
    "# YPred = linear_svc.predict(XTest)\n",
    "\n",
    "# writePrdictedLabelFile(YPred)\n",
    "\n",
    "\n",
    "# rbf_svc = svm.SVC(kernel='rbf')\n",
    "# print rbf_svc.kernel\n",
    "# rbf_svc.fit(XTrain, Y)\n",
    "# # print 'SVM Starting'\n",
    "# # To predict a new input XTest\n",
    "# YPred = rbf_svc.predict(XTest)\n",
    "\n",
    "# writePrdictedLabelFile(YPred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Ridge Regression\n",
    "# from sklearn import linear_model\n",
    "\n",
    "# # Setting the regularization parameter: generalized Cross-Validation\n",
    "\n",
    "# from sklearn import linear_model\n",
    "# clfRidge = linear_model.RidgeCV(alphas=[0.1, 1.0, 10.0])\n",
    "# clfRidge.fit(XTrain, Y)       \n",
    "\n",
    "# alpha = clfRidge.alpha_ \n",
    "# print alpha \n",
    "\n",
    "# clfRidge = linear_model.Ridge(alpha)\n",
    "# clfRidge.fit(XTrain, Y) \n",
    "\n",
    "# print clfRidge.coef_\n",
    "# print clfRidge.intercept_ \n",
    "\n",
    "\n",
    "##Decision Tree\n",
    "# from sklearn import tree\n",
    "# clf = tree.DecisionTreeClassifier()\n",
    "# clf = clf.fit(XTrain, Y)\n",
    "# YPred = clf.predict(XTest)\n",
    "# writePrdictedLabelFile(YPred)\n",
    "\n",
    "\n",
    "##Decision Tree with Dimensionality Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "# from sklearn import tree\n",
    "# # pca = PCA(n_components=48)\n",
    "# # pca.fit(XTest)\n",
    "# # XTest = pca.transform(XTest)\n",
    "# # pca.fit(XTrain)\n",
    "# # XTrain = pca.transform(XTrain)\n",
    "# clf = tree.DecisionTreeClassifier()\n",
    "# clf = clf.fit(XTrain, Y)\n",
    "# YPred = clf.predict(XTest)\n",
    "# writePrdictedLabelFile(YPred)\n",
    "\n",
    "\n",
    "##Random Forests\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# pca = PCA(n_components=48)\n",
    "# pca.fit(XTest)\n",
    "# XTest = pca.transform(XTest)\n",
    "# pca.fit(XTrain)\n",
    "# XTrain = pca.transform(XTrain)\n",
    "# clf = RandomForestClassifier(n_estimators=10)\n",
    "# clf = clf.fit(XTrain, Y)\n",
    "# YPred = clf.predict(XTest)\n",
    "# writePrdictedLabelFile(YPred)\n",
    "\n",
    "print 'completed'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.linear_model import Ridge\n",
    "    \n",
    "# fig, ax_rows = plt.subplots(4, 2, figsize=(8, 10))\n",
    "\n",
    "# def plot_coefficients(est, ax, label=None, yscale='log'):\n",
    "#     coef = est.steps[-1][1].coef_.ravel()\n",
    "#     if yscale == 'log':\n",
    "#         ax.semilogy(np.abs(coef), marker='o', label=label)\n",
    "#         ax.set_ylim((1e-1, 1e8))\n",
    "#     else:\n",
    "#         ax.plot(np.abs(coef), marker='o', label=label)\n",
    "#     ax.set_ylabel('abs(coefficient)')\n",
    "#     ax.set_xlabel('coefficients')\n",
    "#     ax.set_xlim((1, 9))\n",
    "\n",
    "# degree = 9\n",
    "# alphas = [0.0, 1e-8, 1e-5, 1e-1]\n",
    "# for alpha, ax_row in zip(alphas, ax_rows):\n",
    "#     ax_left, ax_right = ax_row\n",
    "#     est = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=alpha))\n",
    "#     est.fit(X_train, y_train)\n",
    "#     plot_approximation(est, ax_left, label='alpha=%r' % alpha)\n",
    "#     plot_coefficients(est, ax_right, label='Ridge(alpha=%r) coefficients' % alpha)\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writePrdictedLabelFile(YPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
