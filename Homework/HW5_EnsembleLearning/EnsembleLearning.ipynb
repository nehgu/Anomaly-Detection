{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "XTrain = []\n",
    "YTrain = []\n",
    "XTest = []\n",
    "YTest = []\n",
    "\n",
    "#XTrain = np.loadtxt(os.getcwd() + r'/UCI HAR Dataset/UCI HAR Dataset/train/X_train.txt', delimiter=\" \", dtype='str')\n",
    "xTrainFileName = os.getcwd() + r'/UCI HAR Dataset/UCI HAR Dataset/train/X_train.txt'\n",
    "with open(xTrainFileName, \"r\") as myfile:\n",
    "    for line in myfile:\n",
    "        XTrain.append(map(float, line.split()))\n",
    "        \n",
    "              \n",
    "yTrainFileName = os.getcwd() + r'/UCI HAR Dataset/UCI HAR Dataset/train/y_train.txt'\n",
    "with open(yTrainFileName, \"r\") as myfile:\n",
    "    for line in myfile:\n",
    "        YTrain.append(int(line.strip()))\n",
    "\n",
    "XTrain = np.asarray(XTrain)\n",
    "YTrain = np.asarray(YTrain)\n",
    "\n",
    "xTestFileName = os.getcwd() + r'/UCI HAR Dataset/UCI HAR Dataset/test/X_test.txt'\n",
    "with open(xTestFileName, \"r\") as myfile:\n",
    "    for line in myfile:\n",
    "        XTest.append(map(float, line.split()))\n",
    "        \n",
    "              \n",
    "yTestFileName = os.getcwd() + r'/UCI HAR Dataset/UCI HAR Dataset/test/y_test.txt'\n",
    "with open(yTestFileName, \"r\") as myfile:\n",
    "    for line in myfile:\n",
    "        YTest.append(int(line.strip()))\n",
    "        \n",
    "        \n",
    "XTest = np.asarray(XTest)\n",
    "YTest = np.asarray(YTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the time series data using Fast Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.fftpack import fft\n",
    "# The first 265 columns represent the acceleration for all the axes in the Time Series Domain\n",
    "xfTrain = fft(XTrain[:,0:265])\n",
    "xfTest = fft(XTest[:,0:265])\n",
    "\n",
    "# timeSeriesFFT = []\n",
    "# for row in xf:\n",
    "#     timeSeriesFFT.append(row)\n",
    "\n",
    "# print (np.array(timeSeriesFFT)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate the acceleration for all the axes into one feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XTrain = np.append(XTrain[:,265:], xfTrain , 1)\n",
    "XTest = np.append(XTest[:,265:], xfTest , 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try out different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def classifyRandomForestClassifier(XTrain, XTest, YTrain, YTest):\n",
    "    clf = RandomForestClassifier(n_estimators=10)\n",
    "    clf.fit(XTrain, YTrain)\n",
    "    YPred = clf.predict(XTest)\n",
    "    diff = YPred - YTest\n",
    "    score = diff[diff == 0].size\n",
    "    return (100.0 * score)/(YPred.size), YPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#K Nearest Neighbours Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def classifyKNNClassifier(XTrain, XTest, YTrain, YTest):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "    YPred = neigh.fit(XTrain, YTrain).predict(XTest)\n",
    "    diff = YPred - YTest\n",
    "    score = diff[diff == 0].size\n",
    "    return (100.0 * score)/(YPred.size), YPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Gaussian Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "def classifyGaussianNaiveBayesClassifier(XTrain, XTest, YTrain, YTest):\n",
    "    gnb = GaussianNB()\n",
    "    YPred = gnb.fit(XTrain, YTrain).predict(XTest)\n",
    "    diff = YPred - YTest\n",
    "    score = diff[diff == 0].size\n",
    "    return (100.0 * score)/(YPred.size), YPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Multi Class SVM\n",
    "from sklearn import svm\n",
    "from sklearn.svm import NuSVC\n",
    "def classifyMultiClassSVMClassifier(XTrain, XTest, YTrain, YTest):\n",
    "    YPred = svm.SVC(kernel='linear').fit(XTrain, YTrain).predict(XTest)\n",
    "    diff = YPred - YTest\n",
    "    score = diff[diff == 0].size\n",
    "    return (100.0 * score)/(YPred.size), YPred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify the signals into different activities. <br> </br> Use Leave-One-Out crossvalidation, where you test on one user and train on the rest of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn.cross_validation.LeaveOneOut(n=7352)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "X = xf\n",
    "y = YTrain\n",
    "N = 7352\n",
    "loo = cross_validation.LeaveOneOut(N)\n",
    "print loo\n",
    "y = y.ravel()\n",
    "\n",
    "# score = 0.0\n",
    "# for train_index, test_index in loo:\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "#     score += classifyRandomForestClassifier(X_train, X_test,  y_train, y_test)\n",
    "\n",
    "# score = score/N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Stratified K Fold Cross Validation\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "def stratifiedKFoldVal(XTrain, YTrain, classify):\n",
    "    n_folds = 10\n",
    "    totalScore = 0.0\n",
    "    skf = StratifiedKFold(YTrain, n_folds)\n",
    "    for train_index, test_index in skf:\n",
    "        X_train, X_test = XTrain[train_index], XTrain[test_index]\n",
    "        y_train, y_test = YTrain[train_index], YTrain[test_index]\n",
    "        score, YPred = classify(X_train, X_test,  y_train, y_test)\n",
    "        totalScore += score\n",
    "    return totalScore/n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.3063892113\n"
     ]
    }
   ],
   "source": [
    "classify = classifyRandomForestClassifier\n",
    "score = stratifiedKFoldVal(XTrain, YTrain, classify)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.9656713006\n"
     ]
    }
   ],
   "source": [
    "classify = classifyKNNClassifier\n",
    "score = stratifiedKFoldVal(XTrain, YTrain, classify)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.9947542962\n"
     ]
    }
   ],
   "source": [
    "classify = classifyGaussianNaiveBayesClassifier\n",
    "score = stratifiedKFoldVal(XTrain, YTrain, classify)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.6985423391\n"
     ]
    }
   ],
   "source": [
    "classify = classifyMultiClassSVMClassifier\n",
    "score = stratifiedKFoldVal(XTrain, YTrain, classify)\n",
    "print score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement a Python framework for mixture of experts, \n",
    "### where the user can assign multiple classifiers to a different region of the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "np.random.seed(9)\n",
    "X_train, X_test, y_train, y_test = train_test_split(XTrain, YTrain, test_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-174-c0f6a9d7fa54>:2: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(classifiersList)*2,len(splitFeatIdx))\n"
     ]
    }
   ],
   "source": [
    "def EnsembleFeatureSplitClassifiers(X_train, X_test, y_train, y_test, splitFeatIdx, classifiersList = [classifyRandomForestClassifier, classifyKNNClassifier, classifyGaussianNaiveBayesClassifier, classifyMultiClassSVMClassifier]):\n",
    "    assert(len(classifiersList)*2,len(splitFeatIdx))\n",
    "    \n",
    "#     s1,YPred1 = classifyRandomForestClassifier(X_train[:,splitFeatIdx[0]:splitFeatIdx[1]], X_test[:,splitFeatIdx[0]:splitFeatIdx[1]], y_train, y_test)\n",
    "#     s2,YPred2 = classifyKNNClassifier(X_train[:,splitFeatIdx[2]:splitFeatIdx[3]], X_test[:,splitFeatIdx[2]:splitFeatIdx[3]], y_train, y_test)\n",
    "#     s3,YPred3 = classifyGaussianNaiveBayesClassifier(X_train[:,splitFeatIdx[4]:splitFeatIdx[5]], X_test[:,splitFeatIdx[4]:splitFeatIdx[5]], y_train, y_test)\n",
    "#     s4,YPred4 = classifyMultiClassSVMClassifier(X_train[:,splitFeatIdx[6]:splitFeatIdx[7]], X_test[:,splitFeatIdx[6]:splitFeatIdx[7]], y_train, y_test)\n",
    "#     # Combine Y Predicted values from different classifiers\n",
    "#     XCombinedOp = np.column_stack((YPred1, YPred2, YPred3, YPred4))\n",
    "\n",
    "    YPred = []\n",
    "    i = 0\n",
    "    for classifier in classifiersList:\n",
    "        s,ypred = classifier(X_train[:,splitFeatIdx[i]:splitFeatIdx[i+1]], X_test[:,splitFeatIdx[i]:splitFeatIdx[i+1]], y_train, y_test)\n",
    "        i = i + 2\n",
    "        # Combine Y Predicted values from different classifiers\n",
    "        YPred.append(ypred)\n",
    "    \n",
    "    XCombinedOp = np.column_stack(YPred)\n",
    "    \n",
    "    return XCombinedOp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The results of these classifiers are forwarded to an additional classifier \n",
    "### (e.g. neural network) that is trained to optimally combine the output from the first stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sknn.mlp import Classifier, Layer\n",
    "\n",
    "def NeuralNetworkCombiner(XCombinedOpTrain, y_train, XCombinedOpTest, YTest):\n",
    "    nn = Classifier(layers=[Layer(\"Rectifier\", units=100),Layer(\"Linear\")],\n",
    "        learning_rate=0.02,\n",
    "        n_iter=10)\n",
    "    nn.fit(XCombinedOpTrain, y_train)\n",
    "    YTestPred = nn.predict(XCombinedOpTest)\n",
    "    diff = YTestPred - YTest.reshape(YTestPred.shape)\n",
    "    score = diff[diff == 0].size\n",
    "    score = (100.0 * score)/(YTestPred.size)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using disjoint features for all classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "58.46623685103495"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featSplit = [0,265,265,420,420,555,555,561]\n",
    "\n",
    "# With only 1 classifier\n",
    "classifiersList = [classifyKNNClassifier]\n",
    "XCombinedOpTrain = EnsembleFeatureSplitClassifiers(X_train, X_test, y_train, y_test, featSplit, classifiersList)\n",
    "XCombinedOpTest = EnsembleFeatureSplitClassifiers(X_train, XTest, y_train, YTest, featSplit, classifiersList)\n",
    "NeuralNetworkCombiner(XCombinedOpTrain, y_test, XCombinedOpTest, YTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63.48829317950458"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With 2 classifiers\n",
    "classifiersList = [classifyKNNClassifier, classifyGaussianNaiveBayesClassifier]\n",
    "\n",
    "XCombinedOpTrain = EnsembleFeatureSplitClassifiers(X_train, X_test, y_train, y_test, featSplit, classifiersList)\n",
    "XCombinedOpTest = EnsembleFeatureSplitClassifiers(X_train, XTest, y_train, YTest, featSplit, classifiersList)\n",
    "NeuralNetworkCombiner(XCombinedOpTrain, y_test, XCombinedOpTest, YTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49.541907024092296"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With 3 classifiers\n",
    "classifiersList = [classifyKNNClassifier, classifyGaussianNaiveBayesClassifier, classifyMultiClassSVMClassifier]\n",
    "featSplit = [0,265,265,420,420,555,555,561]\n",
    "\n",
    "XCombinedOpTrain = EnsembleFeatureSplitClassifiers(X_train, X_test, y_train, y_test, featSplit, classifiersList)\n",
    "XCombinedOpTest = EnsembleFeatureSplitClassifiers(X_train, XTest, y_train, YTest, featSplit, classifiersList)\n",
    "NeuralNetworkCombiner(XCombinedOpTrain, y_test, XCombinedOpTest, YTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64.47234475738038"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With 4 classifiers\n",
    "classifiersList = [classifyRandomForestClassifier, classifyKNNClassifier, classifyGaussianNaiveBayesClassifier, classifyMultiClassSVMClassifier]\n",
    "featSplit = [0,265,265,420,420,555,555,561]\n",
    "\n",
    "XCombinedOpTrain = EnsembleFeatureSplitClassifiers(X_train, X_test, y_train, y_test, featSplit)\n",
    "XCombinedOpTest = EnsembleFeatureSplitClassifiers(X_train, XTest, y_train, YTest, featSplit)\n",
    "NeuralNetworkCombiner(XCombinedOpTrain, y_test, XCombinedOpTest, YTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the accuracy change if you use overlapping regions instead of disjunct ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72.31082456735663"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using overlapping features for all classifiers\n",
    "featSplit = [0,220,100,280,170,345,280,561]\n",
    "XCombinedOpTrain = EnsembleFeatureSplitClassifiers(X_train, X_test, y_train, y_test, featSplit)\n",
    "XCombinedOpTest = EnsembleFeatureSplitClassifiers(X_train, XTest, y_train, YTest, featSplit)\n",
    "NeuralNetworkCombiner(XCombinedOpTrain, y_test, XCombinedOpTest, YTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sknn:\u001b[0;33mWARNING: Expecting `Softmax` type for the last layer in classifier.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "86.83406854428232"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using all features for all classifiers\n",
    "featSplit = [0,561,0,561,0,561,0,561]\n",
    "XCombinedOpTrain = EnsembleFeatureSplitClassifiers(X_train, X_test, y_train, y_test, featSplit)\n",
    "XCombinedOpTest = EnsembleFeatureSplitClassifiers(X_train, XTest, y_train, YTest, featSplit)\n",
    "NeuralNetworkCombiner(XCombinedOpTrain, y_test, XCombinedOpTest, YTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.neural_network import BernoulliRBM\n",
    "# model = BernoulliRBM(n_components=2, n_iter=50)\n",
    "# model.fit(XCombinedOpTrain, y_test)\n",
    "# print model.intercept_hidden_\n",
    "# print model.intercept_visible_\n",
    "# print model.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph of change of accuracy w.r.t. the number of used classifiers in the first stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there any benefit of using mixture of experts on this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
