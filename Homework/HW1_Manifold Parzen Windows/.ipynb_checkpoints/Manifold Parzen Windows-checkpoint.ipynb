{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import seaborn as sns\n",
    "# Implemented from Vincent, Pascal, and Yoshua Bengio. Manifold parzen windows. Advances in neural information processing systems. 2002.\n",
    "\n",
    "# Algorithm for Local Gaussian\n",
    "def LocalGaussian(xTest, Xi, Vi, lambdai, d, var, n):\n",
    "    \n",
    "    # Define the variables.\n",
    "    r = 0\n",
    "    q = 0\n",
    "    \n",
    "    # Step 1:\n",
    "    #r = d* math.log(2*math.pi) + sum(math.log(lambdai + var) + (n-d)*math.log(var))\n",
    "    \n",
    "    # Step 2:\n",
    "    #q = (1/var)* ((xTest - Xi)**2) + sum(((1/lambdai) - (1/var))*((np.transpose(Vi)*(xTest - Xi))**2))\n",
    "    \n",
    "    \n",
    "    r = d* math.log(2*math.pi) + (math.log(lambdai + var) + (n-d)*math.log(var))\n",
    "    \n",
    "    # Step 2:\n",
    "    q = (1/var)* (math.sqrt(sum((xTest - Xi)**2))) + (((1/lambdai) - (1/var))*(math.sqrt(sum((np.transpose(Vi)*(xTest - Xi))**2))))\n",
    "    \n",
    "    return math.exp(-0.5 * (r+q))\n",
    "\n",
    "# Algorithm for Manifold Parzen\n",
    "def ManifoldParzenTrain(X, d, k, var):\n",
    "    \n",
    "    # Define the variables.\n",
    "    \n",
    "    (l,n) = X.shape\n",
    "    lambdaVec = []\n",
    "    V = []\n",
    "    \n",
    "    # Step 1:\n",
    "    for i in xrange(l):\n",
    "        # Step 2: kNN \n",
    "        neigh = NearestNeighbors(n_neighbors=k)\n",
    "        neigh.fit(X) \n",
    "        NearestNeighbors(algorithm='auto', leaf_size=30)\n",
    "        [dist, idx] = neigh.kneighbors(X[i])\n",
    "        \n",
    "        M = []\n",
    "        for j in np.nditer(idx):\n",
    "            M = np.append(M, X[j] - X[i]) # *np.ones(k,n)\n",
    "        \n",
    "        newM = M.reshape((k,n))\n",
    "        \n",
    "        \n",
    "        # Step 3:\n",
    "        Ui, s, Vi = np.linalg.svd(newM, full_matrices=True)\n",
    "        \n",
    "        # Take top d elements from s\n",
    "        s_d = s[0:d]\n",
    "        \n",
    "        \n",
    "        V = np.append(V,Vi)\n",
    "        \n",
    "        # Step 4: Can be vectorized to remove the for loop.\n",
    "        lambdai = []\n",
    "        for a in xrange(d):\n",
    "            \n",
    "            #lambdai[a] = var + np.diag(s_d)/l\n",
    "        \n",
    "            lambdaVec = np.append(lambdaVec, var + np.diag(s_d)/l)\n",
    "        \n",
    "    Model = {\"ip\":X, \"eigenVec\":V, \"lambda\": lambdaVec, \"neighbors\":k, \"dim\":d, \"variance\":var}\n",
    "        \n",
    "    return Model\n",
    "\n",
    "# Algorithm for checking distribution of Test point\n",
    "def DistributionTestPoint(xTest, Model):\n",
    "    \n",
    "    # Define the variables.\n",
    "    # Step 1:\n",
    "    s = 0\n",
    "    manifoldParzenEstimate = 0\n",
    "    \n",
    "    X = Model[\"ip\"]\n",
    "    V = Model[\"eigenVec\"]\n",
    "    lambdaVec = Model[\"lambda\"]\n",
    "    k = Model[\"neighbors\"]\n",
    "    d = Model[\"dim\"]\n",
    "    var = Model[\"variance\"]\n",
    "    \n",
    "    (l,n) = X.shape\n",
    "    \n",
    "    # Step 2:\n",
    "    for i in xrange(l):\n",
    "        \n",
    "        # Step 3:\n",
    "        s = s + LocalGaussian(xTest, X[i], V[i], lambdaVec[i], d, var, n)\n",
    "    \n",
    "    manifoldParzenEstimate = s/l\n",
    "    \n",
    "    return manifoldParzenEstimate\n",
    "\n",
    "\n",
    "#Read the dataset\n",
    "# inputData = np.loadtxt('spiral.txt',dtype='float',usecols=(0,1),ndmin=2)\n",
    "inputData = np.loadtxt('spiral1.txt',dtype='float',usecols=(0,1),ndmin=2)\n",
    "train, test = train_test_split(inputData, test_size = 0.2, random_state=42)\n",
    "# Input, test = train_test_split(inputData, test_size = 0.2, random_state=42)\n",
    "# train, crossval = train_test_split(Input, test_size = 0.2, random_state=40)\n",
    "\n",
    "#Using Gaussian Kernel Density Estimation\n",
    "pdf = KernelDensity(bandwidth=0.4)\n",
    "pdf.fit(train)\n",
    "res = []\n",
    "for data in test:\n",
    "#     print np.exp(pdf.score_samples(data))[0]\n",
    "    res.append(np.exp(pdf.score_samples(data))[0])\n",
    "# print \"KDE OP:\",res\n",
    "# res = pdf.score_samples([15,3])\n",
    "# res1 = pdf.score([15,3])\n",
    "# print np.exp(res),np.exp(res1)\n",
    "# print res\n",
    "\n",
    "# Perform Manifold Parzen Estimate\n",
    "# X = inputData\n",
    "X = train\n",
    "d = 1\n",
    "k = 10\n",
    "var = 2\n",
    "\n",
    "Model = ManifoldParzenTrain(X, d, k, var)\n",
    "# manifoldParzenEstimate =  DistributionTestPoint([15,3], Model)\n",
    "resMPE = []\n",
    "for data in test:\n",
    "    resMPE.append(DistributionTestPoint(data, Model))\n",
    "# print \"MPE OP:\",resMPE\n",
    "# print len(resMPE),len(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
