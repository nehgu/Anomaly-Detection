{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 Approaches in anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "mat = scipy.io.loadmat('oc_514.mat')\n",
    "train = mat['x']\n",
    "xtrain = train[0,0][0]\n",
    "\n",
    "# Commented split of train and test as using k-fold cross validation approach for outlier detection.\n",
    "X_train, X_test = train_test_split(\n",
    "   xtrain, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection using KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Using Gaussian Kernel Density Estimation\n",
    "def GaussianKDE(X_train, X_test):\n",
    "    #pdf = KernelDensity(bandwidth=0.25, kernel='linear')\n",
    "    pdf = KernelDensity(bandwidth=0.1, kernel='gaussian')\n",
    "    pdf.fit(X_train)\n",
    "    resTrain = []\n",
    "    resTest = []\n",
    "    \n",
    "    for data in X_train[:,:]:\n",
    "        resTrain.append(np.exp(pdf.score_samples(data))[0])\n",
    "    \n",
    "    for data in X_test[:,:]:\n",
    "        resTest.append(np.exp(pdf.score_samples(data))[0])\n",
    "    \n",
    "    nresTrain = np.array(resTrain)\n",
    "    nresTest = np.array(resTest)\n",
    "    \n",
    "    # Assumption: \"Normal data instances occur in high probability\n",
    "    # regions of a stochastic model, while anomalies occur in the low\n",
    "    # probability regions of the stochastic model.\"\n",
    "    return nresTrain[nresTrain <= 0.05].size, nresTest[nresTest <= 0.05].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 81.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cross Validation using K-Fold so that every data sample contributes in Training\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "X_train = xtrain\n",
    "#print X_train.shape\n",
    "n_folds = 5\n",
    "kf = KFold(420, n_folds)\n",
    "error_train = error_test = 0\n",
    "for train, test in kf:\n",
    "    #print train,test\n",
    "    n_error_train, n_error_test = GaussianKDE(X_train[train,:], X_train[test,:])\n",
    "    error_test += n_error_test\n",
    "    error_train += n_error_train\n",
    "    \n",
    "print float(error_train)/n_folds , float(error_test)/n_folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 105\n"
     ]
    }
   ],
   "source": [
    "# Split the train and test set in the ratio of 3:1\n",
    "\n",
    "n_error_train, n_error_test = GaussianKDE(X_train[:315,:], X_train[315:,:])\n",
    "\n",
    "\n",
    "print n_error_train, n_error_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of KDE for Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using KDE we got 81 anomalies out of 420 samples. This performs poorly as the number of anomalies is higher than the expected number of 183 as defined in the webpage of the dataset. Kernel Density Estimation (KDE) can be performed in any number of dimensions, though in practice the curse of dimensionality causes its performance to degrade in high dimensions which is the case with our dataset as it has 278 features.\n"
     ]
    }
   ],
   "source": [
    "print \"Using KDE we got\", (error_train + error_test)/n_folds , \"anomalies out of 420 samples. This performs poorly as the number of anomalies is higher than the expected number of 183 as defined in the webpage of the dataset. Kernel Density Estimation (KDE) can be performed in any number of dimensions, though in practice the curse of dimensionality causes its performance to degrade in high dimensions which is the case with our dataset as it has 278 features.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection using One Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#xtrain = train[0,0][0]\n",
    "def OutlierUsingOneClassSVM(X_train, X_test):\n",
    "\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.font_manager\n",
    "    from sklearn import svm\n",
    "    import scipy.io as sio\n",
    "\n",
    "    #xx, yy = np.meshgrid(np.linspace(-5, 5, 500), np.linspace(-5, 5, 500))\n",
    "\n",
    "    # Generate train data\n",
    "    #X = 0.3 * np.random.randn(100, 2)\n",
    "    #X_train = np.r_[X + 2, X - 2]\n",
    "    # Generate some regular novel observations\n",
    "    #X = 0.3 * np.random.randn(20, 2)\n",
    "    #X_test = np.r_[X + 2, X - 2]\n",
    "    # Generate some abnormal novel observations\n",
    "    #X_outliers = np.random.uniform(low=-4, high=4, size=(20, 2))\n",
    "\n",
    "\n",
    "    # fit the model\n",
    "    #clf = svm.OneClassSVM(nu=0.2, kernel=\"rbf\", gamma=0.1)\n",
    "    clf = svm.OneClassSVM(nu=0.435, kernel=\"linear\", gamma=0.1)\n",
    "    clf.fit(X_train)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    #y_pred_outliers = clf.predict(X_outliers)\n",
    "    n_error_train = y_pred_train[y_pred_train == -1].size\n",
    "    n_error_test = y_pred_test[y_pred_test == -1].size\n",
    "    #n_error_outliers = y_pred_outliers[y_pred_outliers == 1].size\n",
    "\n",
    "    # Plots\n",
    "    # plot the line, the points, and the nearest vectors to the plane\n",
    "#     Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "#     Z = Z.reshape(xx.shape)\n",
    "\n",
    "#     plt.title(\"Novelty Detection\")\n",
    "#     plt.contourf(xx, yy, Z, levels=np.linspace(Z.min(), 0, 7), cmap=plt.cm.Blues_r)\n",
    "#     a = plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors='red')\n",
    "#     plt.contourf(xx, yy, Z, levels=[0, Z.max()], colors='orange')\n",
    "\n",
    "#     b1 = plt.scatter(X_train[:, 0], X_train[:, 1], c='white')\n",
    "#     b2 = plt.scatter(X_test[:, 0], X_test[:, 1], c='green')\n",
    "#     # #c = plt.scatter(X_outliers[:, 0], X_outliers[:, 1], c='red')\n",
    "#     plt.axis('tight')\n",
    "#     plt.xlim((-5, 5))\n",
    "#     plt.ylim((-5, 5))\n",
    "#     plt.legend([a.collections[0], b1, b2], #, c],\n",
    "#                [\"learned frontier\", \"training observations\",\n",
    "#                 \"new regular observations\", \"new abnormal observations\"],\n",
    "#                loc=\"upper left\",\n",
    "#                prop=matplotlib.font_manager.FontProperties(size=11))\n",
    "#     plt.xlabel(\n",
    "#         \"error train: %d/200 ; errors novel regular: %d/40 ; \"\n",
    "#         \"errors novel abnormal:\"\n",
    "#         % (n_error_train, n_error_test)) #, n_error_outliers))\n",
    "#     plt.show()\n",
    "\n",
    "    return n_error_train, n_error_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420L, 278L)\n",
      "146.8 37.0\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation using K-Fold so that every data sample contributes in Training\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "X_train = xtrain\n",
    "print X_train.shape\n",
    "n_folds = 5\n",
    "kf = KFold(420, n_folds)\n",
    "error_train = error_test = 0\n",
    "for train, test in kf:\n",
    "    #print train,test\n",
    "    n_error_train, n_error_test = OutlierUsingOneClassSVM(X_train[train,:], X_train[test,:])\n",
    "    #print error_train, error_test\n",
    "    #print n_error_train, n_error_test\n",
    "    error_train += n_error_train\n",
    "    error_test += n_error_test\n",
    "    \n",
    "print float(error_train)/n_folds, float(error_test)/n_folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147 37\n"
     ]
    }
   ],
   "source": [
    "# Split the train and test set in the ratio of 4:1\n",
    "n_error_train, n_error_test = OutlierUsingOneClassSVM(X_train[:336,:], X_train[336:,:])\n",
    "\n",
    "print n_error_train, n_error_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance using One Class SVM for Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using One Class SVM we got 184 anomalies out of 420 samples. This performs well after tuning the kernel to be linear and with appropriate parameters as the number of anomalies matches the expected number of 183 as defined in the webpage of the dataset.\n"
     ]
    }
   ],
   "source": [
    "print \"Using One Class SVM we got\", (n_error_train + n_error_test) , \"anomalies out of 420 samples. This performs well after tuning the kernel to be linear and with appropriate parameters as the number of anomalies matches the expected number of 183 as defined in the webpage of the dataset.\" \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
