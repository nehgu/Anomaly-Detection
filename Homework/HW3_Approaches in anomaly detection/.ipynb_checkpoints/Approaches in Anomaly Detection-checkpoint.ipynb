{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 Approaches in anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "mat = scipy.io.loadmat('oc_514.mat')\n",
    "train = mat['x']\n",
    "xtrain = train[0,0][0]\n",
    "\n",
    "# Commented split of train and test as using k-fold cross validation approach for outlier detection.\n",
    "X_train, X_test = train_test_split(\n",
    "   xtrain, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection using KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Using Gaussian Kernel Density Estimation\n",
    "def GaussianKDE(X_train, X_test):\n",
    "    #pdf = KernelDensity(bandwidth=0.25, kernel='linear')\n",
    "    pdf = KernelDensity(bandwidth=0.1, kernel='gaussian')\n",
    "    pdf.fit(X_train)\n",
    "    resTrain = []\n",
    "    resTest = []\n",
    "    \n",
    "    for data in X_train[:,:]:\n",
    "        resTrain.append(np.exp(pdf.score_samples(data))[0])\n",
    "    \n",
    "    for data in X_test[:,:]:\n",
    "        resTest.append(np.exp(pdf.score_samples(data))[0])\n",
    "    \n",
    "    nresTrain = np.array(resTrain)\n",
    "    nresTest = np.array(resTest)\n",
    "    \n",
    "    # Assumption: \"Normal data instances occur in high probability\n",
    "    # regions of a stochastic model, while anomalies occur in the low\n",
    "    # probability regions of the stochastic model.\"\n",
    "    return nresTrain[nresTrain <= 0.05].size, nresTest[nresTest <= 0.05].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 81.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cross Validation using K-Fold so that every data sample contributes in Training\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "X_train = xtrain\n",
    "#print X_train.shape\n",
    "n_folds = 5\n",
    "kf = KFold(420, n_folds)\n",
    "error_train = error_test = 0\n",
    "for train, test in kf:\n",
    "    #print train,test\n",
    "    n_error_train, n_error_test = GaussianKDE(X_train[train,:], X_train[test,:])\n",
    "    error_test += n_error_test\n",
    "    error_train += n_error_train\n",
    "    \n",
    "print float(error_train)/n_folds , float(error_test)/n_folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 105\n"
     ]
    }
   ],
   "source": [
    "# Split the train and test set in the ratio of 3:1\n",
    "\n",
    "n_error_train, n_error_test = GaussianKDE(X_train[:315,:], X_train[315:,:])\n",
    "\n",
    "\n",
    "print n_error_train, n_error_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance using KDE for Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using KDE we got 81 anomalies out of 420 samples. This performs poorly as the number of anomalies is higher than the expected number of 183 as defined in the webpage of the dataset. Kernel Density Estimation (KDE) can be performed in any number of dimensions, though in practice the curse of dimensionality causes its performance to degrade in high dimensions which is the case with our dataset as it has 278 features.\n"
     ]
    }
   ],
   "source": [
    "print \"Using KDE we got\", (error_train + error_test)/n_folds , \"anomalies out of 420 samples. This performs poorly as the number of anomalies is higher than the expected number of 183 as defined in the webpage of the dataset. Kernel Density Estimation (KDE) can be performed in any number of dimensions, though in practice the curse of dimensionality causes its performance to degrade in high dimensions which is the case with our dataset as it has 278 features.\" "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
